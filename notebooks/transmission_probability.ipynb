{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The autoreload extension allows you to tweak the code in the imported modules\n",
    "# and rerun cells to reflect the changes.\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "# this allows us to output the dictionary structure\n",
    "%reload_ext ipy_dict_hierarchy\n",
    "# matplotlib settings to look decent in the notebook\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# the helpers are in the `/ana/` folder.\n",
    "import sys\n",
    "sys.path.append(\"./../\")\n",
    "from ana import ana_helper as ah\n",
    "from ana import plot_helper as ph\n",
    "from ana import paper_plots as pp\n",
    "from ana import ndim_helper as nh\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# setup logging for notebook\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s | %(levelname)-8s | %(name)-12s | %(message)s\",\n",
    "    datefmt=\"%y-%m-%d %H:%M\",\n",
    ")\n",
    "log = logging.getLogger(\"notebook\")\n",
    "log.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a connectivity overview\n",
    "h5f = ah.prepare_file(f\"{pp.p_sim}/lif/raw_directed/stim=0_k=1_kin=30_rate=80.0_stimrate=30.0_rep=000.hdf5\")\n",
    "\n",
    "_, ax = plt.subplots()\n",
    "ph.plot_connectivity_layout(h5f, ax=ax)\n",
    "ax.get_figure().savefig(f\"{pp.p_fo}/sm_rev_directed_connectivity.png\", transparent=True, dpi=900)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim = nh.load_ndim_h5f(\"./../dat/simulations/lif/processed/ndim_directed.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim[\"rag_burst_core_delays\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim[\"rag_burst_seqs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.setLevel(logging.INFO)\n",
    "pp._error_bar_cap_style = \"round\"\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=2, figsize=(3, 4), sharex=True, gridspec_kw={\"height_ratios\": [1, 2]}\n",
    ")\n",
    "\n",
    "\n",
    "def propagation_status(seq_as_int):\n",
    "    # 0 -> 1 is a successful propagation\n",
    "    # the int for that is 12\n",
    "    # an unseccesufl propagation is a 0\n",
    "    # the int for that is 1\n",
    "    success = ah.seq_to_int([0, 1])\n",
    "    failure = ah.seq_to_int([0])\n",
    "\n",
    "    if seq_as_int == success:\n",
    "        return 1\n",
    "    elif seq_as_int == failure:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "\n",
    "for tdx, target in enumerate(ndim[\"rag_burst_seqs\"][\"stim_mods\"].values):\n",
    "    nd_seqs = ndim[\"rag_burst_seqs\"].sel(stim_mods=target)\n",
    "\n",
    "    y_l = dict()\n",
    "    y_m = dict()\n",
    "    y_h = dict()\n",
    "\n",
    "    y_l_count = dict()\n",
    "    y_m_count = dict()\n",
    "    y_h_count = dict()\n",
    "\n",
    "    for s in nd_seqs[\"stim_rate\"].values:\n",
    "        # each rep has an array of different length\n",
    "        reps = nd_seqs.sel(stim_rate=s).squeeze()\n",
    "\n",
    "        rep_level_prob = []\n",
    "        rep_level_counts = []\n",
    "        aggregated_success = 0\n",
    "        aggregated_failure = 0\n",
    "        aggregated_irrelevant = 0\n",
    "\n",
    "        # for each rep, get all sequences, one for each burst\n",
    "        for rdx, sequences in enumerate(reps):\n",
    "\n",
    "            # to get the propagation probability, we need to filter\n",
    "            # sequences that propagated (1), those that did not (0) and those that\n",
    "            # started in accidentally in the wrong module (-1)\n",
    "\n",
    "            prepped = np.array([propagation_status(s) for s in sequences.values[()]])\n",
    "            irrelevant = prepped[prepped == -1]\n",
    "            success = prepped[prepped == 1]\n",
    "            failure = prepped[prepped == 0]\n",
    "\n",
    "            aggregated_success += len(success)\n",
    "            aggregated_failure += len(failure)\n",
    "            aggregated_irrelevant += len(irrelevant)\n",
    "\n",
    "            log.debug(\n",
    "                f\"rep {rdx} | irrelevant: {len(irrelevant)} | success: {len(success)} |\"\n",
    "                f\" failure: {len(failure)}\"\n",
    "            )\n",
    "\n",
    "            total = len(success) + len(failure)\n",
    "            rep_level_prob.append(len(success) / total)\n",
    "            rep_level_counts.append(total)\n",
    "\n",
    "        # y_m[s] = np.median(rep_level_prob)\n",
    "        # y_l[s] = np.quantile(rep_level_prob, 0.975)\n",
    "        # y_h[s] = np.quantile(rep_level_prob, 0.025)\n",
    "\n",
    "        y_m[s] = np.mean(rep_level_prob)\n",
    "        y_l[s] = y_m[s] + np.std(rep_level_prob) / np.sqrt(len(rep_level_prob))\n",
    "        y_h[s] = y_m[s] - np.std(rep_level_prob) / np.sqrt(len(rep_level_prob))\n",
    "\n",
    "        y_m_count[s] = np.mean(rep_level_counts)\n",
    "        y_l_count[s] = y_m_count[s] + np.std(rep_level_counts) / np.sqrt(\n",
    "            len(rep_level_counts)\n",
    "        )\n",
    "        y_h_count[s] = y_m_count[s] - np.std(rep_level_counts) / np.sqrt(\n",
    "            len(rep_level_counts)\n",
    "        )\n",
    "\n",
    "    pp.errorsticks(\n",
    "        center=np.array(list(y_m.keys())) + 0.5 * tdx,\n",
    "        mid=y_m.values(),\n",
    "        thin=np.array([list(y_l.values()), list(y_h.values())]).T,\n",
    "        ax=axes[1],\n",
    "        color=f\"C{tdx}\",\n",
    "        label=f\"targeting module: {target.decode()}\",\n",
    "    )\n",
    "\n",
    "    # number of bursts, we recorded for 5 minutes\n",
    "    pp.errorsticks(\n",
    "        center=np.array(list(y_m_count.keys())) + 0.5 * tdx,\n",
    "        mid=y_m_count.values(),\n",
    "        thin=np.array([list(y_l_count.values()), list(y_h_count.values())]).T,\n",
    "        ax=axes[0],\n",
    "        color=f\"C{tdx}\",\n",
    "        label=f\"_targeting module: {target.decode()}\",\n",
    "    )\n",
    "\n",
    "axes[1].set_ylim(0, 1)\n",
    "axes[1].set_xlabel(\"Stimulus rate\")\n",
    "axes[1].set_ylabel(\"Probability to propagate\")\n",
    "axes[1].legend()\n",
    "\n",
    "sns.despine(ax=axes[0], bottom=True)\n",
    "axes[0].tick_params(axis=\"x\", which=\"both\", bottom=False, top=False, labelbottom=False)\n",
    "axes[0].set_ylabel(\"Number of events\\nin module 0 (5 min)\")\n",
    "\n",
    "axes[0].grid(axis=\"y\", color=\"0.9\", linewidth=0.5)\n",
    "axes[1].grid(axis=\"y\", color=\"0.9\", linewidth=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.setLevel(logging.INFO)\n",
    "pp._error_bar_cap_style = \"round\"\n",
    "import pandas as pd\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(4, 3))\n",
    "\n",
    "\n",
    "data = pd.concat(\n",
    "    [\n",
    "        ndim[\"rag_burst_seqs\"].to_dataframe(name=\"sequences\"),\n",
    "        ndim[\"rag_resources_mod_0\"].to_dataframe(name=\"source_resources\"),\n",
    "        ndim[\"rag_resources_mod_1\"].to_dataframe(name=\"target_resources\"),\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "data.reset_index(inplace=True)\n",
    "data[\"stim_mods\"] = data[\"stim_mods\"].apply(lambda x: x.decode())\n",
    "\n",
    "# create a long list of bursts, with status and resources in target, source\n",
    "rows_to_add = []\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "\n",
    "    seqs = row[\"sequences\"][:]\n",
    "\n",
    "    # to get the propagation probability, we need to filter\n",
    "    # sequences that propagated (1), those that did not (0) and those that\n",
    "    # started in accidentally in the wrong module (-1)\n",
    "\n",
    "    prepped = np.array([propagation_status(s) for s in seqs])\n",
    "\n",
    "    # build new rows by expanding\n",
    "    num_bursts = len(seqs)\n",
    "    rows_to_add.extend(\n",
    "        [\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"stim_mods\": [row[\"stim_mods\"]] * num_bursts,\n",
    "                    \"stim_rate\": [row[\"stim_rate\"]] * num_bursts,\n",
    "                    \"target_resources\": row[\"target_resources\"],\n",
    "                    \"source_resources\": row[\"source_resources\"],\n",
    "                    \"status\": prepped,\n",
    "                }\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "df = pd.concat(rows_to_add)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query(\"status == 0 and stim_mods == '0'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_df = df.query(\"status != -1\")\n",
    "fig, ax = plt.subplots(figsize=(5/2.54, 3 / 2.54))\n",
    "hb = ax.hexbin(\n",
    "    x=this_df[\"source_resources\"],\n",
    "    y=this_df[\"target_resources\"],\n",
    "    C=this_df[\"status\"],\n",
    "    gridsize=15,\n",
    "    mincnt=4,\n",
    "    marginals=False,\n",
    "    linewidths=0.1,\n",
    "    cmap=\"Blues\",\n",
    "    reduce_C_function = lambda arr: float(np.sum(arr) / len(arr)),\n",
    "    vmin=0,\n",
    "    vmax=1,\n",
    ")\n",
    "cb = fig.colorbar(hb, ax=ax)\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_xlabel(\"Resources (left module)\")\n",
    "ax.set_ylabel(\"Resources\\n(right module)\")\n",
    "cb.set_label(\"Probability\\nto propagate\")\n",
    "ax.get_figure().savefig(f\"{pp.p_fo}/sm_rev_propagation_probability.pdf\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(\n",
    "    # data=df.query(\"status == 1 and stim_mods == '1'\"),\n",
    "    data=df.query(\"status == -1\"),\n",
    "    x=\"source_resources\",\n",
    "    y=\"target_resources\",\n",
    "    hue=\"stim_mods\",\n",
    "    # alpha=0.1,\n",
    "    marker=\"+\",\n",
    "    s=5,\n",
    "    lw=0,\n",
    "    alpha=0.2,\n",
    ")\n",
    "# ax.set_xlim(0, 1)\n",
    "# ax.set_ylim(0, 1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "965c20fcf1f3c4c2d622bc2f64d0068a6184ac03d438688c29b2bf2de8d7c0a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
