{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model of Spiking Neurons\n",
    "## Getting Started\n",
    "\n",
    "The code to generate spiking data from simulations of leaky integrate and fire neurons is can be found in `src/quadratic_integrate_and_fire.py`.\n",
    "It uses the Brian2 simulator and creates a hdf5 file containing spike times (and meta data) for every set of parameters.\n",
    "\n",
    "For example,\n",
    "```\n",
    ">>> python ./src/quadratic_integrate_and_fire.py -o ./dat/simulations/lif/test.hdf5 -d 300 -equil 60 -r 80\n",
    "```\n",
    "will run a simulation that lasts 300 seconds.\n",
    "\n",
    "Here is a list of the model parameters, that can be specified at run time:\n",
    "```\n",
    ">>> python ./src/quadratic_integrate_and_fire.py -h \n",
    "\n",
    "  -h, --help            show this help message and exit\n",
    "  -o FILE               output path\n",
    "  -jA 45.0              AMPA current strength, in mV\n",
    "  -jG 50.0              GABA current strength, in mV\n",
    "  -jM 15.0              Minis (noise amplitude), in mV\n",
    "  -r 80.0               Poisson rate (minis), all neurons, in Hz\n",
    "  -tD 20.0              Characteristic recovery time, in seconds\n",
    "  -s 42                 RNG seed\n",
    "  -k 5                  Number of bridging axons\n",
    "  -d 1200               Recording duration, in seconds\n",
    "  -equil 120, --equilibrate 120\n",
    "                        Equilibration duration, in seconds\n",
    "  -stim off             if/how to stimulate: 'off', 'poisson'\n",
    "  -stim_rate 20         additional rate in stimulated mods, in Hz\n",
    "  -mod 0                modules to stimulate, e.g. `0`, or `02` for multiple\n",
    "  --bridge_weight 1.0   synaptic weight of bridge neurons [0, 1]\n",
    "  --inhibition_fraction 0.2\n",
    "                        fraction of neurons that should be inhibitory\n",
    "  --record-state-dt 25.0\n",
    "                        time step for recording state variables, in ms.\n",
    "                        use 0.5 to get smooth resource-rate cycles\n",
    "```\n",
    "\n",
    "After creating running a simulation, we can use the helper functions in `ana/plot_helper.py` to visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The autoreload extension allows you to tweak the code in the imported modules\n",
    "# and rerun cells to reflect the changes.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# this allows us to output the dictionary structure\n",
    "%load_ext ipy_dict_hierarchy\n",
    "# matplotlib settings to look decent in the notebook\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# the helpers are in the `/ana/` folder.\n",
    "import sys\n",
    "sys.path.append(\"./../\")\n",
    "from ana import ana_helper as ah\n",
    "from ana import plot_helper as ph\n",
    "from ana import paper_plots as pp\n",
    "\n",
    "# setup logging for notebook\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s | %(levelname)-8s | %(name)-12s | %(message)s\",\n",
    "    datefmt=\"%y-%m-%d %H:%M\",\n",
    "    level=logging.INFO,\n",
    ")\n",
    "log = logging.getLogger(\"notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>> python ./src/quadratic_integrate_and_fire.py -o ./dat/simulations/lif/test.hdf5 -d 300 -equil 60 -r 80\n",
    "# lets load and take a look at the file we have created\n",
    "h5f = ah.prepare_file(\"./../dat/simulations/lif/test.hdf5\")\n",
    "h5f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `h5f` above is just a nested dictionary that corresponds to a loaded hdf5 file. We use those a lot throught the analysis and plotting routines. Whenever an analysis is run, it can use details from known places and add the results directly to the `/ana/` dictionary (without writing to disk)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# silence the detailed outputs\n",
    "ph.log.setLevel(\"ERROR\")\n",
    "# and produce overview panels for the loaded file\n",
    "ph.overview_dynamic(h5f);\n",
    "ph.overview_topology(h5f);\n",
    "# Note, when using an interactive matplotlib backend, you can zoom and pan the figures"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Data\n",
    "We ran two sets of simulations: stimulating the whole system, or only two modules.\n",
    "For example, the `python ./run/create_pars_for_global_stimulation.py` produces `run/parameters.tsv` with the parameter combinations we used, each line can be called from terminal.\n",
    "By default, each line corresponds to one realization and produces one hdf5 file (like above) in `dat/simulations/lif/raw`.\n",
    "\n",
    "Now you would call each line in a bash for-loop, or rather, have a look at `run/submit_to_cluster.sh`\n",
    "For our example of 2k realizations and an SGE: `qsub -t 1-2000 ./run/submit_to_cluster.sh`\n",
    "\n",
    "Note on compute time:\n",
    "We used 50 realizations per coordinate and topology. Each of those (2k in total) runs approximately in real-time, and we simulate 30 minute recordings.\n",
    "\n",
    "### Data for rate-resource cycles\n",
    "To get the rate-resource cylces smooth, we have to record the resource variable during the simulations at high time resolution (which needs a lot of disk space, ~4GB for 30 min).\n",
    "This can be enabled by passing `--record-state-dt 0.5` to `src/quadratic_integrate_and_fire.py`.\n",
    "If you just want to reproduce the figures from the manuscript, you can quickly run a few simulations:\n",
    "```\n",
    "python ./src/quadratic_integrate_and_fire.py -o ./dat/simulations/lif/raw/highres_stim=off_k=-1_jA=45.0_jG=50.0_jM=15.0_tD=20.0_rate=80.0_rep=001.hdf5 -k -1 -d 1800 -equil 300 -s 6102 --record-state-dt 0.5 -r 80\n",
    "python ./src/quadratic_integrate_and_fire.py -o ./dat/simulations/lif/raw/highres_stim=off_k=-1_jA=45.0_jG=50.0_jM=15.0_tD=20.0_rate=90.0_rep=001.hdf5 -k -1 -d 1800 -equil 300 -s 6102 --record-state-dt 0.5 -r 90\n",
    "python ./src/quadratic_integrate_and_fire.py -o ./dat/simulations/lif/raw/highres_stim=off_k=1_jA=45.0_jG=50.0_jM=15.0_tD=20.0_rate=80.0_rep=001.hdf5 -k 1 -d 1800 -equil 300 -s 6002 --record-state-dt 0.5 -r 80\n",
    "python ./src/quadratic_integrate_and_fire.py -o ./dat/simulations/lif/raw/highres_stim=off_k=1_jA=45.0_jG=50.0_jM=15.0_tD=20.0_rate=90.0_rep=001.hdf5 -k 1 -d 1800 -equil 300 -s 6002 --record-state-dt 0.5 -r 90\n",
    "python ./src/quadratic_integrate_and_fire.py -o ./dat/simulations/lif/raw/highres_stim=off_k=5_jA=45.0_jG=50.0_jM=15.0_tD=20.0_rate=80.0_rep=001.hdf5 -k 5 -d 1800 -equil 300 -s 6102 --record-state-dt 0.5 -r 80\n",
    "python ./src/quadratic_integrate_and_fire.py -o ./dat/simulations/lif/raw/highres_stim=off_k=5_jA=45.0_jG=50.0_jM=15.0_tD=20.0_rate=90.0_rep=001.hdf5 -k 5 -d 1800 -equil 300 -s 6102 --record-state-dt 0.5 -r 90\n",
    "python ./src/quadratic_integrate_and_fire.py -o ./dat/simulations/lif/raw/highres_stim=off_k=10_jA=45.0_jG=50.0_jM=15.0_tD=20.0_rate=80.0_rep=001.hdf5 -k 10 -d 1800 -equil 300 -s 6202 --record-state-dt 0.5 -r 80\n",
    "python ./src/quadratic_integrate_and_fire.py -o ./dat/simulations/lif/raw/highres_stim=off_k=10_jA=45.0_jG=50.0_jM=15.0_tD=20.0_rate=90.0_rep=001.hdf5 -k 10 -d 1800 -equil 300 -s 6202 --record-state-dt 0.5 -r 90\n",
    "```\n",
    "\n",
    "## Analysing\n",
    "### Partial stimulation\n",
    "The simulations with two targeted modules are analysed by the same script as the experiments\n",
    "`ana/process_conditions.py`, it produces a pre-stim comparison.\n",
    "\n",
    "The script has the (input and output) filenames hardcoded. It globs the input files that match the right file pattern, depending on `-t sim_partial`, `-t sim_partial_no_inhib` or `-t sim` (global stimulation) and creates and output file matching the `-t` argument.\n",
    "For instance,\n",
    "```\n",
    "python ./ana/process_conditions.py -t sim_partial -i ./dat/simulations/lif/raw/ -o ./dat/simulations/lif/processed/\n",
    "```\n",
    "Scans all files in `/dat/simulations/lif/raw/` and outputs `./dat/simulations/lif/processed/k=5_partial.hdf5`.\n",
    "\n",
    "### Outdated: Global stimulation (removed / reworked in Rev 1)\n",
    "For the global stimulation, we mainly varied the input rate (`-r`) which ended up on the x-axis of most plots.\n",
    "\n",
    "In order to combine the many runs in the `dat/simulations/lif/raw/` folder, we use the script in `ana/ndim_merge.py`. It takes a wildcarded file path, runs a lot of analysis, and merges the results into a high-dimensional (x-array like) hdf5 file. As this can take a while, it uses dask and can delegate to a cluster.\n",
    "```\n",
    "python ./ana/ndim_merge.py -i './dat/simulations/lif/raw/stim=off*jM=15*tD=20*.hdf5' -o ./dat/simulations/lif/processed/ndim.hdf5 -c num_cores\n",
    "```\n",
    "\n",
    "Both of the above scripts are wrappers (handling mostly the IO) around the lower-level analysis routines that can be found in `ana/ana_helper.py`. To reproduce where each observable in the processed dataframes comes from, I recommend to skim the scripts above and then jump to the corresponding part in the `ana_helper`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note 23-01-09:\n",
    "below are a plot functions that I used during revision 1, the have not been fully cleaned / documented, yet.\n",
    "\n",
    "## Plots from the paper\n",
    "### Partial Stimulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig 3 pooled violins and scatter for all realizations with k=3\n",
    "\n",
    "pp.log.setLevel(\"INFO\")\n",
    "# print(pp.fig_3_r1.__doc__)\n",
    "pp.show_xlabel = True\n",
    "pp.show_ylabel = True\n",
    "# for k in [\"1\", \"3\", \"5\", \"10\", \"20\", \"-1\"]:\n",
    "for k in [\"3\"]:\n",
    "    try:\n",
    "        pp.fig_3_r1(\n",
    "            # note: inconsistent file naming.\n",
    "            pd_path = f\"{pp.p_sim}/lif/processed_alpha/k={k}_partial.hdf5\",\n",
    "            out_suffix=f\"_k={k}_partial\",\n",
    "            combine_panels=False,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig 3, observables for different regions depending on k.\n",
    "# used to be in figure 4, todo: refactor backend.\n",
    "\n",
    "# print(pp.fig_4.__doc__)\n",
    "pp.show_legend = False\n",
    "pp.log.setLevel(\"INFO\")\n",
    "pp._error_bar_cap_style = \"round\"\n",
    "pp.show_title = False\n",
    "pp.show_ylabel = True\n",
    "pp.show_xlabel = False\n",
    "pp.fig_4_r1(\n",
    "    pd_path=f\"{pp.p_sim}/lif/processed/ndim.hdf5\",\n",
    "    out_prefix=f\"{pp.p_fo}/sim_f4_\",\n",
    "    x_dim=\"k_inter\",\n",
    ")\n",
    "#\n",
    "pp._error_bar_cap_style = \"butt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig 3 table of plotted values for sm\n",
    "\n",
    "pp.log.setLevel(\"INFO\")\n",
    "ds = pp.table_for_fig_3()\n",
    "ds.rename(columns=pp._lif_labels, inplace=True)\n",
    "ds.rename(columns=lambda x: x.replace(\"sys_median_correlation_\", \"\"), inplace=True)\n",
    "ds.to_excel(f\"{pp.p_sim}/lif/processed/fig_3_table.xlsx\", engine=\"openpyxl\")\n",
    "ds.to_latex(\n",
    "    f\"{pp.p_sim}/lif/processed/fig_3_table.tex\",\n",
    "    na_rep=\"\",\n",
    "    bold_rows=False,\n",
    "    multirow=True,\n",
    "    multicolumn=True,\n",
    "    float_format=\"{:2.2f}\".format,\n",
    ")\n",
    "ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig 3 rasters\n",
    "pp.show_xlabel = False\n",
    "pp.show_ylabel = False\n",
    "pp.show_title = False\n",
    "pp.fig_3_r1_snapshots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Fig 4 module contributions\n",
    "\n",
    "pp.show_xlabel = True\n",
    "pp.show_ylabel = True\n",
    "pp.show_title = False\n",
    "\n",
    "coords = pp.reference_coordinates\n",
    "coords[\"k_inter\"] = 3\n",
    "\n",
    "ax = pp.sim_modules_participating_in_bursts(\n",
    "    f\"{pp.p_sim}/lif/processed/ndim.hdf5\",\n",
    "    simulation_coordinates=coords,\n",
    "    xlim_for_fill=None,\n",
    "    xlim_for_points=[0, 40],\n",
    "    dim1=\"stim_rate\",\n",
    "    drop_zero_len=False,\n",
    ")\n",
    "\n",
    "ax.set_xlim(0, 35)\n",
    "ax.set_xlabel(\"External input (Hz)\" if pp.show_xlabel else \"\")\n",
    "ax.set_ylabel(\"Fraction of events\\nspanning\" if pp.show_ylabel else \"\")\n",
    "\n",
    "\n",
    "pp.sns.despine(ax=ax, offset=2.5)\n",
    "pp.cc.set_size(ax, w=1.8, h=1.0, l=0.8, b=0.5, r=0.2, t=0.2)\n",
    "\n",
    "ax.get_figure().savefig(f\"{pp.p_fo}/lif_partial_modules_participating_in_bursts.pdf\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig 4 module correlation\n",
    "\n",
    "pp.log.setLevel(\"INFO\")\n",
    "\n",
    "pp.show_xlabel = True\n",
    "pp.show_ylabel = True\n",
    "pp.show_title = False\n",
    "\n",
    "dset = pp.nh.load_ndim_h5f(f\"{pp.p_sim}/lif/processed/ndim.hdf5\")\n",
    "cc = pp.cc\n",
    "\n",
    "ax = None\n",
    "for kdx, k in enumerate([0, 1, 3, 5, 10]):\n",
    "    coords = pp.reference_coordinates.copy()\n",
    "    coords[\"k_inter\"] = k\n",
    "    coords[\"stim_mods\"] = \"02\"\n",
    "    coords[\"rate\"] = 80.0\n",
    "    ax = pp.sim_plot_obs_from_ndim(\n",
    "        dset = dset,\n",
    "        coords = coords,\n",
    "        observable = \"mod_median_correlation_within_stim\",\n",
    "        x_dim = \"stim_rate\",\n",
    "        ax = ax,\n",
    "        errortype=\"sem\",\n",
    "        estimator=\"mean\",\n",
    "        color= cc.alpha_to_solid_on_bg(pp.colors[\"stim\"], cc.fade(kdx, 5, invert=True)),\n",
    "        clip_on=False,\n",
    "    )\n",
    "\n",
    "ax.set_xlim(0, 35)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.xaxis.set_major_locator(pp.matplotlib.ticker.MultipleLocator(10))\n",
    "ax.xaxis.set_minor_locator(pp.matplotlib.ticker.MultipleLocator(5))\n",
    "ax.yaxis.set_major_locator(pp.matplotlib.ticker.MultipleLocator(0.5))\n",
    "ax.yaxis.set_minor_locator(pp.matplotlib.ticker.MultipleLocator(0.1))\n",
    "ax.set_xlabel(\"External input (Hz)\" if pp.show_xlabel else \"\")\n",
    "ax.set_ylabel(\"Module\\ncorrelation\" if pp.show_ylabel else \"\")\n",
    "\n",
    "pp.sns.despine(ax=ax, offset=2.5)\n",
    "pp.cc.set_size(ax, w=1.8, h=1.0, l=0.8, b=0.5, r=0.2, t=0.2)\n",
    "ax.get_figure().savefig(f\"{pp.p_fo}/f4_lif_correlation_vs_rate.pdf\", dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resource cycles, rasters, topology\n",
    "\n",
    "# print(pp.fig_4_snapshots.__doc__)\n",
    "pp.show_xlabel = False\n",
    "pp.show_ylabel = False\n",
    "pp.show_title = False\n",
    "pp.fig_4_r1_snapshots(\n",
    "    k_in=30,\n",
    "    do_rasters=True,\n",
    "    do_topo=True,\n",
    "    # plotting resource cycles takes very long.\n",
    "    do_cycles=True,\n",
    "    out_prefix=f\"{pp.p_fo}/sim_s3_lif_\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# degree distributions\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from src import topology as topo\n",
    "\n",
    "pp.show_title = True\n",
    "pp.show_xlabel = True\n",
    "pp.show_ylabel = True\n",
    "\n",
    "k_in_target = 30\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=4, sharex=True, sharey=True, figsize=(6.5, 2))\n",
    "for idx, k in enumerate([1, 3, 10, -1]):\n",
    "    a = topo.find_alpha_for_target_in_degree(\n",
    "        k_inter=k, k_in_target=k_in_target, rerun=False\n",
    "    )\n",
    "    ax = axes[idx]\n",
    "    # seaborns distplot makes glitchy legend entries, we fix them in post.\n",
    "    # black -> total\n",
    "    # purple -> external\n",
    "    # green -> internal\n",
    "    pp.sim_degrees_sampled(k_inter=k, num_reps=20, ax=ax, par_alpha=a)\n",
    "    if pp.show_title:\n",
    "        ax.set_title(f\"k={k}\" if k != -1 else \"merged\")\n",
    "\n",
    "    ax.set_xlim(0,60)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(f\"{pp.p_fo}/in_degrees_kin={k_in_target}.pdf\", bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Blocking Inhibition\" by setting jG=0\n",
    "\n",
    "pp.show_xlabel = False\n",
    "pp.show_ylabel = True\n",
    "pp.show_title = False\n",
    "\n",
    "pp.fig_3(\n",
    "    pd_path=f\"{pp.p_sim}/lif/processed/k=3_partial_no_inhib.hdf5\",\n",
    "    raw_paths = [\n",
    "        f\"{pp.p_sim}/lif/raw/stim=02_k=3_kin=30_jA=45.0_jG=0.0_jM=15.0_tD=20.0_rate=80.0_stimrate=0.0_rep=001.hdf5\",\n",
    "        f\"{pp.p_sim}/lif/raw/stim=02_k=3_kin=30_jA=45.0_jG=0.0_jM=15.0_tD=20.0_rate=80.0_stimrate=20.0_rep=001.hdf5\",\n",
    "    ],\n",
    "    out_prefix=f\"{pp.p_fo}/sim_s6_\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Reviewer answer, dependence on bin size\n",
    "# runs the same as fig 4 but loads different preprocessed files.\n",
    "# print(pp.fig_4.__doc__)\n",
    "pp.show_legend = False\n",
    "pp.log.setLevel(\"INFO\")\n",
    "pp._error_bar_cap_style = \"round\"\n",
    "pp.show_title = False\n",
    "pp.show_ylabel = True\n",
    "pp.show_xlabel = False\n",
    "pp.fig_4_r1(\n",
    "    pd_path=f\"{pp.p_sim}/lif/processed/ndim_250rij_22-12-19.hdf5\",\n",
    "    out_prefix=f\"{pp.p_fo}/sim_sr_rij250_\",\n",
    "    x_dim=\"k_inter\",\n",
    ")\n",
    "#\n",
    "pp._error_bar_cap_style = \"butt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Reviewer reply: comparing k=0 to merged\n",
    "pp.show_legend = False\n",
    "pp.log.setLevel(\"ERROR\")\n",
    "pp.show_title = False\n",
    "pp.show_ylabel = True\n",
    "pp.show_xlabel = True\n",
    "# requires hardcoding in the function definition, `iters`\n",
    "pp.fig_4_r1(\n",
    "    x_dim=\"stim_rate\",\n",
    "    out_prefix=f\"{pp.p_fo}/sim_sr_0merged_\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "965c20fcf1f3c4c2d622bc2f64d0068a6184ac03d438688c29b2bf2de8d7c0a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
