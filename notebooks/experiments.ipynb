{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Experimental Data\n",
    "\n",
    "Experimental data will be available for download from our [Gnode repository](https://gin.g-node.org/pspitzner/stimulating_modular_cultures) (after acceptance).\n",
    "Place the downloaded files in the base directroy of _this_ repo, i.e. `./dat/experiments/`\n",
    "\n",
    "Most of the analysis is the same for experiments and simulations.\n",
    "The comparison across conditions is implemented in a stand-alone script `ana/process_conditions.py`, that can be run from a terminal and takes a the following arguments:\n",
    "* `-i` the base path to the folder where the data is stored.\n",
    "* `-t` the type of experiment (yields the right subfolders and file names):\n",
    "    - `exp` for main results, from optogenetic stimulation and different topologies\n",
    "    - `exp_chemical` for the experiments with KCl\n",
    "    - `exp_bic` for the experiments with Bicuculline\n",
    "    - `sim_partial` for simulations where only part of the system was targeted.\n",
    "* `-o` where to store the output path.\n",
    "\n",
    "To create the preprocessed data, navigate to the base directory and run:\n",
    "```bash\n",
    "python ./ana/process_conditions.py -t exp -i ./dat/experiments/raw/  -o ./dat/experiments/processed/\n",
    "python ./ana/process_conditions.py -t exp_chemical -i ./dat/experiments/raw/ -o ./dat/experiments/processed/\n",
    "python ./ana/process_conditions.py -t exp_bic -i ./dat/experiments/raw/ -o ./dat/experiments/processed/\n",
    "```\n",
    "\n",
    "\n",
    "This should yield the following files:\n",
    "```bash\n",
    ">>> tree -L 2 --dirsfirst ./dat/experiments/processed/\n",
    "dat/experiments/processed/\n",
    "├── 1b\n",
    "│   ├── 210315_A\n",
    "│   ├── 210315_C\n",
    "│   ├── 210405_C\n",
    "│   ├── 210406_B\n",
    "│   ├── 210406_C\n",
    "│   ├── 210719_B\n",
    "│   ├── 210719_C\n",
    "│   └── 210726_B\n",
    "├── 3b\n",
    "│   ├── 210316_A\n",
    "│   ...\n",
    "├── Bicuculline_1b\n",
    "│   ├── 210907_1bB\n",
    "│   ...\n",
    "├── KCl_1b\n",
    "│   ├── 210420_C\n",
    "│   ...\n",
    "├── merged\n",
    "│   ├── 210401_A\n",
    "│   ...\n",
    "├── 1b.hdf5\n",
    "├── 3b.hdf5\n",
    "├── Bicuculline_1b.hdf5\n",
    "├── KCl_1b.hdf5\n",
    "└── merged.hdf5\n",
    "```\n",
    "\n",
    "where the `*.hdf5` files contain the preprocessed data and the folders for each experiment have some additional info. See also `save_analysed_h5f` in `ana/process_conditions.py`.\n",
    "\n",
    "Low-level plotting functions are contained in `ana/plot_helper.py` and\n",
    "the higher-level wrappers as well as further analysis are in `ana/paper_plots.py`.\n",
    "In particular, most contend of this notebook can also be found in `paper_plots.py/fig_x()`\n",
    "\n",
    "Experiments are depicted in Figures 1 and 2, and in the Supplemental Material.\n",
    "For fine-grained control, we produced every figure panel as a stand-alone and combined them later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The autoreload extension allows you to tweak the code in the imported modules (`pp`)\n",
    "# and rerun cells to reflect the changes.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext ipy_dict_hierarchy\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../ana/\")\n",
    "sys.path.append(\"./../\")\n",
    "\n",
    "from ana import paper_plots as pp\n",
    "# reduce the printed output, we have lots of details on the INFO level.\n",
    "pp.log.setLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pp.fig_1.__doc__)\n",
    "pp.show_ylabel = True\n",
    "pp.show_title = True\n",
    "pp.fig_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pp.fig_2.__doc__)\n",
    "pp.log.setLevel(\"ERROR\")\n",
    "pp.show_xlabel = False\n",
    "pp.show_ylabel = True\n",
    "pp.show_title = True\n",
    "pp.fig_2(\n",
    "    pd_folder = f\"{pp.p_exp}/processed\",\n",
    "    out_prefix = f\"{pp.p_fo}/exp_f2_\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table s5\n",
    "df = pp.table_for_violins()\n",
    "# we want core delay in miliseconds\n",
    "df[\"Core delays (ms)\"] = df[\"Core delays\"].apply(lambda x: x * 1000)\n",
    "df = df.drop(\"Core delays\", axis=1)\n",
    "\n",
    "df.to_excel(f\"{pp.p_exp}/processed/fig_2_table_violins.xlsx\", engine=\"openpyxl\")\n",
    "df.to_latex(\n",
    "    f\"{pp.p_exp}/processed/fig_2_table_violins.tex\",\n",
    "    na_rep=\"\",\n",
    "    bold_rows=False,\n",
    "    multirow=True,\n",
    "    multicolumn=True,\n",
    "    float_format=\"{:3.2f}\".format,\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table s4\n",
    "df = pp.table_for_rij()\n",
    "df.to_excel(f\"{pp.p_exp}/processed/fig_2_table_rij_barplots.xlsx\", engine=\"openpyxl\")\n",
    "df.to_latex(\n",
    "    f\"{pp.p_exp}/processed/fig_2_table_rij_barplots.tex\",\n",
    "    na_rep=\"\",\n",
    "    bold_rows=False,\n",
    "    multirow=True,\n",
    "    multicolumn=True,\n",
    "    float_format=\"{:3.2f}\".format,\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supplemental Material and Statistical Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pp.fig_sm_exp_trialwise_observables.__doc__)\n",
    "pp.log.setLevel(\"ERROR\")\n",
    "pp.show_xlabel = True\n",
    "pp.show_ylabel = True\n",
    "pp.show_title = False\n",
    "pp.fig_sm_exp_trialwise_observables(\n",
    "    pd_folder=f\"{pp.p_exp}/processed\",\n",
    "    out_prefix=f\"{pp.p_fo}/exp_sr_rij500_\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table s6\n",
    "df = pp.table_for_trials()\n",
    "# add the number of trials of the trial data frame to the layout description\n",
    "df = df.reset_index()\n",
    "df[\"layout\"] = df[\"layout\"] + \" ($N=\" + df[\"trials\"].map(str) + \"$ realizations)\"\n",
    "df = df.drop(\"trials\", axis=1)\n",
    "df = df.set_index([\"layout\", \"condition\", \"kind\"])\n",
    "\n",
    "df.to_excel(f\"{pp.p_exp}/processed/fig_2_table_trial_estimates.xlsx\", engine=\"openpyxl\")\n",
    "df.to_latex(\n",
    "    f\"{pp.p_exp}/processed/fig_2_table_trial_estimates.tex\",\n",
    "    na_rep=\"\",\n",
    "    bold_rows=False,\n",
    "    multirow=True,\n",
    "    multicolumn=True,\n",
    "    float_format=\"{:3.2f}\".format,\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NHST\n",
    "Frequentist perspective, with Null-hypothesis of pre- and stim conditions being equal.\n",
    "The table below contains p-values from two-sided, paired-sample t-tests\n",
    "(corresponding to the stick-plots above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table s1\n",
    "# the test results are logged at INFO level and\n",
    "# returned as a pandas dataframe.\n",
    "pp.log.setLevel(\"WARNING\")\n",
    "nhst_stats = pp.nhst_pairwise_for_trials(\n",
    "    observables=[\n",
    "        \"Mean Rate\",\n",
    "        \"Median Fraction\", # this is the event size\n",
    "        \"Median Neuron Correlation\",\n",
    "        \"Functional Complexity\",\n",
    "        \"Mean IBI\",\n",
    "        \"Mean Core delays\",\n",
    "    ],\n",
    "    layouts=[\"1b\", \"3b\", \"merged\", \"KCl_1b\"],\n",
    ")\n",
    "\n",
    "nhst_stats.to_excel(f\"{pp.p_exp}/processed/fig_2_table_pvals.xlsx\", engine=\"openpyxl\")\n",
    "nhst_stats.to_latex(\n",
    "    f\"{pp.p_exp}/processed/fig_2_table_pvals.tex\",\n",
    "    na_rep=\"\",\n",
    "    bold_rows=False,\n",
    "    multirow=True,\n",
    "    multicolumn=True,\n",
    "    float_format=\"{:5.4f}\".format,\n",
    ")\n",
    "nhst_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian\n",
    "Taking a bayesian perspective, we ask what changes of the observables are _credible_ given the recorded data. We assume the differences between the conditions to follow a student-t distribution, sample the posterior of the _mean of the differences_ and list:\n",
    "* the highest density intervals (HDI) of the posterior distribution\n",
    "* the probability of direction (PD)\n",
    "* PD converted to a two-sided p-value\n",
    "\n",
    "#TODO: add refs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesian_stats = pp.bayesian_best_for_trials(\n",
    "    observables=[\"Mean Correlation\", \"Mean Fraction\", \"Functional Complexity\"],\n",
    "    layouts=[\"1b\", \"3b\", \"merged\", \"KCl_1b\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesian_stats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "965c20fcf1f3c4c2d622bc2f64d0068a6184ac03d438688c29b2bf2de8d7c0a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
